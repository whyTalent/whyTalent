# NLP - GPT模型







## GPT模型

GPT（Generative Pre-trained Transformer）是OpenAI开发的一系列大型自然语言处理模型，基于Transformer架构，采用自回归生成策略。GPT模型主要通过预训练和微调两个阶段进行训练。预训练阶段，模型在大量无标签文本数据上进行无监督训练，学习到丰富的语言模式和知识；微调阶段，模型根据特定任务的有标签数据进行监督学习，以提高在特定任务上的表现。



### GPT-1

GPT-1于2018年发布，是基于Transformer的自回归语言模型。GPT-1采用预训练和微调的策略，在大量文本数据上进行无监督预训练，然后针对特定任务进行有监督微调。尽管GPT-1在自然语言生成和理解任务方面取得了一定的成果，但其模型规模和能力相对有限。



GPT-1语言模型是基于“半监督”方法创建的,其由两个阶段组成。在第一个阶段(无监督生成预训练阶段),使用语言模型来设置初始参数。在第二个阶段(受控细致调整阶段),这些参数被逐点调整以适应目前的任务。

为训练GPT-1神经网络,从7000个互联网页面和各种类型的书籍中加载了4.5GB的文本,这提供了11200万个参数——影响算法准确性的变量。

要点:

1. GPT-1采用了两步训练方法,即无监督预训练阶段和受控调整阶段。
2. 预训练阶段使用无监督语言模型来初步学习参数。大量来自不同来源的通用文本数据(4.5GB)被用来训练模型生成可靠的语言序列,从而得到初始参数集。
3. 调整阶段对模型参数进行细致调整,针对特定任务进行监督学习。通过加载更多标记数据对每个组件的每个参数进行单独调整,从而获得更高的性能。
4. GPT-1有11200万个参数,这些参数依赖于组合预训练和调整阶段训练。大量的通用文本数据(11200万个词汇)有助于确保该模型对语言有广泛而又深入的理解。
5. GPT-1取得成功的关键在于向其提供庞大的高质量、多样化的文本数据,以进行无监督预训练。序列调整阶段则专注于特定应用。
6. 总的来说,GPT-1展示了在无监督预训练和迁移学习方面使用语言模型的功效。它为随后由OpenAI和其他人所提出的更强大的Transformer模型铺平了道路。



### GPT-2

GPT-2于2019年发布，模型规模比GPT-1大了许多，具有15亿个参数。GPT-2在自然语言理解和生成方面取得了显著的进步，实现了多种任务，如机器翻译、摘要生成和问答等。然而，GPT-2也引发了关于生成虚假信息和恶意内容的潜在风险的讨论，因此OpenAI最初并未公开发布完整的GPT-2模型。

### GPT-3

GPT-3在2020年发布，是GPT模型的第三代。它的规模更大，拥有1750亿个参数，是当时世界上最大的自然语言处理模型。GPT-3在各种任务上表现出色，例如摘要生成、翻译、问答、编程、诗歌创作等。GPT-3还引入了强化学习，使其在学习过程中能够根据反馈优化自身表现。

GPT-3引入了一种新的训练方法，称为“零次微调”（Zero-shot Learning），这意味着模型无需经过针对特定任务的微调，就可以直接处理多种任务。GPT-3通过在大量无标签文本数据上进行预训练，学习到了丰富的语言模式和知识。

### GPT-3.5

GPT-3.5作为GPT-3的升级版本，在模型性能和安全性方面进行了优化。GPT-3.5在模拟律师考试中的得分相较于GPT-3有了显著提升，排名在考生的倒数10%左右。这一进步表明GPT-3.5在特定任务上的表现有了显著改善。与此同时，OpenAI也在GPT-3.5中加强了对生成内容的安全性和可控性，减少了生成恶意信息和虚假内容的风险。

### GPT-4

GPT-4于2023年3月14日发布，是OpenAI努力扩展深度学习的最新里程碑。GPT-4是一个大型多模态模型（接受图像和文本输入，发出文本输出），虽然在许多现实世界场景中的能力不如人类，但在各种专业和学术基准上表现出人类水平的表现。例如，GPT-4通过模拟律师考试，分数在应试者的前10%左右；相比之下，GPT-3.5的得分在倒数10%左右。

OpenAI花了6个月的时间，使用对抗性测试程序和ChatGPT的经验教训迭代调整GPT-4，从而在真实性、可操纵性和拒绝超出护栏方面取得了有史以来最好的结果（尽管远非完美）。

### 强化学习在GPT模型中的应用

强化学习是一种机器学习方法，使智能体在与环境互动的过程中学习最优策略。从GPT-3开始，强化学习被用于优化模型的生成策略。通过使用强化学习，GPT模型可以根据给定的反馈（如奖励或惩罚）动态地调整其生成策略，以生成更高质量的文本内容。

例如，在对话生成任务中，如果生成的回答与预期答案相符，模型可以获得正向奖励；相反，如果回答不相关或不准确，模型会受到负向惩罚。通过强化学习，GPT模型可以在与环境的交互中不断改进，提高生成内容的质量和准确性。

​    

​          

# 附录



1. [The Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)
2. [How GPT3 Works - Visualizations and Animations](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)
3. [ChatGPT发展历程、原理、技术架构详解和产业未来 （收录于GPT-4/ChatGPT技术与产业分析）](https://zhuanlan.zhihu.com/p/590655677)
4. [预训练语言模型之GPT-1，GPT-2和GPT-3](https://zhuanlan.zhihu.com/p/350017443)
5. [GPT-4要来了！一文看尽大型语言模型的过去、现在、未来](https://wallstreetcn.com/articles/3683983)
6. [ChatGPT：发展历程、原理、技术架构和产业未来！](http://www.uml.org.cn/ai/202302164.asp)

